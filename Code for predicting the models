#importing libaries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
from sklearn.preprocessing import LabelEncoder

# Loading the dataset and printing a few of the data sets to check what it entails
df = pd.read_csv("IRIS.csv")
print(df.head(4))

#getting more info on the dataset
df.info()

#describing the dataset to understand it better
df.describe()

# Selecting (x) and target (y) values
x = df.iloc[:, :4]   # First 4 columns are features
y = df.iloc[:, 4]    # Last column (species) is the target

#getting to know values of x 
print(x.head(4))

#getting to know values of y 
print(y.head(4))

# Converting categorical labels to numeric using LabelEncoder
le = LabelEncoder()
y = le.fit_transform(y)  # Encoding species names into numbers

# Split dataset into training and test sets
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

# Defining and training the model
model = RandomForestRegressor()
model.fit(x_train, y_train)

# Predicting y models based on x values
y_pred_test = model.predict(x_test)
y_pred_train = model.predict(x_train)

# Evaluating the accuracy of the model using R² score
r2 = r2_score(y_test, y_pred_test)
print(f"R² Score: {r2:.2f}")

# Testing the model out based on the feature input: [sepal_length, sepal_width, petal_length, petal_width]
new_sample = np.array([[5.1, 3.5, 1.4, 0.2]])  

# Predict species (returns a numerical value)
predicted_label = model.predict(new_sample)

# Converting numeric prediction back to species name
predicted_species = le.inverse_transform([int(round(predicted_label[0]))])

print(f"Predicted Species: {predicted_species[0]}")
